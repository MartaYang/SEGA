{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n",
      "len(GloVe):2196016\n",
      "wordvector dim:300\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe maps\n",
    "filename = '/data/GloVe_300dWordVector/glove.840B.300d.txt'\n",
    "def loadGloVe(filename):\n",
    "    embeddings_GloVe = {}\n",
    "    f = open(filename)\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0] ## The first entry is the word\n",
    "        coefs = np.asarray(values[1:], dtype='float32') ## These are the vecotrs representing the embedding for the word\n",
    "        embeddings_GloVe[word] = coefs\n",
    "    print('Loaded GloVe!')\n",
    "    f.close()\n",
    "    return embeddings_GloVe\n",
    "embeddings_GloVe = loadGloVe(filename)\n",
    "vocab_size = len(embeddings_GloVe)\n",
    "print('len(GloVe):'+str(vocab_size))\n",
    "embedding_dim = len(embeddings_GloVe['a'])\n",
    "print('wordvector dim:'+str(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['house_finch.n.01', 'robin.n.02', 'triceratops.n.01',\n",
       "       'green_mamba.n.01', 'harvestman.n.01', 'toucan.n.01',\n",
       "       'jellyfish.n.02', 'dugong.n.01', 'walker_hound.n.01',\n",
       "       'saluki.n.01', 'gordon_setter.n.01', 'komondor.n.01', 'boxer.n.04',\n",
       "       'tibetan_mastiff.n.01', 'french_bulldog.n.01', 'newfoundland.n.01',\n",
       "       'miniature_poodle.n.01', 'arctic_fox.n.01', 'ladybug.n.01',\n",
       "       'three-toed_sloth.n.01', 'rock_beauty.n.01',\n",
       "       'aircraft_carrier.n.01', 'ashcan.n.01', 'barrel.n.02',\n",
       "       'beer_bottle.n.01', 'carousel.n.02', 'chime.n.01', 'clog.n.01',\n",
       "       'cocktail_shaker.n.01', 'dishrag.n.01', 'dome.n.04', 'file.n.03',\n",
       "       'fire_screen.n.01', 'frying_pan.n.01', 'hair_slide.n.01',\n",
       "       'holster.n.01', 'lipstick.n.01', 'oboe.n.01', 'organ.n.05',\n",
       "       'parallel_bars.n.01', 'pencil_box.n.01', 'photocopier.n.01',\n",
       "       'prayer_rug.n.01', 'reel.n.03', 'slot.n.07', 'snorkel.n.01',\n",
       "       'solar_dish.n.01', 'spider_web.n.01', 'stage.n.03', 'tank.n.01',\n",
       "       'tile_roof.n.01', 'tobacco_shop.n.01', 'unicycle.n.01',\n",
       "       'upright.n.02', 'wok.n.01', 'worm_fence.n.01', 'yawl.n.01',\n",
       "       'street_sign.n.01', 'consomme.n.01', 'hotdog.n.02', 'orange.n.01',\n",
       "       'cliff.n.01', 'bolete.n.01', 'ear.n.05', 'horizontal_bar.n.01',\n",
       "       'combination_lock.n.01', 'catamaran.n.01', 'poncho.n.01',\n",
       "       'miniskirt.n.01', 'ibizan_hound.n.01', 'white_wolf.n.01',\n",
       "       'rhinoceros_beetle.n.01', 'garbage_truck.n.01', 'carton.n.02',\n",
       "       'ipod.n.01', 'meerkat.n.01', 'missile.n.01', 'cannon.n.02',\n",
       "       'goose.n.01', 'coral_reef.n.01', 'dalmatian.n.02', 'nematode.n.01',\n",
       "       'ant.n.01', 'black-footed_ferret.n.01', 'king_crab.n.03',\n",
       "       'lion.n.01', 'vase.n.01', 'golden_retriever.n.01',\n",
       "       'mixing_bowl.n.01', 'malamute.n.01', 'african_hunting_dog.n.01',\n",
       "       'cuirass.n.01', 'bookshop.n.01', 'crate.n.01', 'hourglass.n.01',\n",
       "       'electric_guitar.n.01', 'trifle.n.01', 'school_bus.n.01',\n",
       "       'theater_curtain.n.01', 'scoreboard.n.01'], dtype='<U24')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_wordnet_synset = np.load(\"/data/FSLDatasets/MiniImagenet/wordnetID_100.npy\")\n",
    "mini_wordnet_synset = mini_wordnet_synset.astype(str)\n",
    "mini_wordnet_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linnet']\n",
      "['robin']\n",
      "['triceratops']\n",
      "['mamba']\n",
      "['harvestman']\n",
      "['toucan']\n",
      "['jellyfish']\n",
      "['dugong']\n",
      "['foxhound']\n",
      "['Saluki']\n",
      "['setter']\n",
      "['komondor']\n",
      "['boxer']\n",
      "['mastiff']\n",
      "['bulldog']\n",
      "['Newfoundland']\n",
      "['poodle']\n",
      "['fox']\n",
      "['ladybug']\n",
      "['ai']\n",
      "['teleost']\n",
      "['carrier']\n",
      "['ashcan']\n",
      "['barrel']\n",
      "['bottle']\n",
      "['carousel']\n",
      "['chime']\n",
      "['clog']\n",
      "['shaker']\n",
      "['dishrag']\n",
      "['dome']\n",
      "['file']\n",
      "['fireguard']\n",
      "['frypan']\n",
      "['clip']\n",
      "['holster']\n",
      "['lipstick']\n",
      "['oboe']\n",
      "['organ']\n",
      "['bars']\n",
      "['box']\n",
      "['photocopier']\n",
      "['rug']\n",
      "['reel']\n",
      "['slot']\n",
      "['snorkel']\n",
      "['reflector']\n",
      "['web']\n",
      "['stage']\n",
      "['tank']\n",
      "['roof']\n",
      "['tobacconist']\n",
      "['unicycle']\n",
      "['upright']\n",
      "['wok']\n",
      "['fence']\n",
      "['yawl']\n",
      "['sign']\n",
      "['consomme']\n",
      "['hotdog']\n",
      "['orange']\n",
      "['cliff']\n",
      "['bolete']\n",
      "['ear']\n",
      "['exerciser']\n",
      "['lock']\n",
      "['catamaran']\n",
      "['poncho']\n",
      "['miniskirt']\n",
      "['hound']\n",
      "['wolf']\n",
      "['beetle']\n",
      "['dustcart']\n",
      "['carton']\n",
      "['iPod']\n",
      "['meerkat']\n",
      "['missile']\n",
      "['cannon']\n",
      "['goose']\n",
      "['reef']\n",
      "['dalmatian']\n",
      "['nematode']\n",
      "['ant']\n",
      "['ferret']\n",
      "['crab']\n",
      "['lion']\n",
      "['vase']\n",
      "['retriever']\n",
      "['bowl']\n",
      "['malamute']\n",
      "['canine']\n",
      "['cuirass']\n",
      "['bookshop']\n",
      "['crate']\n",
      "['hourglass']\n",
      "['guitar']\n",
      "['trifle']\n",
      "['bus']\n",
      "['curtain']\n",
      "['scoreboard']\n"
     ]
    }
   ],
   "source": [
    "label2vec = []\n",
    "for catwnid in mini_wordnet_synset:\n",
    "    target_synset = wn.synset(catwnid)\n",
    "    class_name = []\n",
    "    while 1:\n",
    "        for lemmaname in target_synset.lemma_names():\n",
    "            if lemmaname in embeddings_GloVe.keys():\n",
    "                class_name.append(lemmaname)\n",
    "                break\n",
    "        if len(class_name) == 1:\n",
    "            break\n",
    "        target_synset = target_synset.hypernyms()[0]\n",
    "    print(class_name)\n",
    "    word_embedding = [embeddings_GloVe[x] for x in class_name]\n",
    "    label2vec.append(word_embedding[0])\n",
    "label2vec_path = '/data/FSLDatasets/MiniImagenet/label2vec_glove_miniimagenet.npy'\n",
    "np.save(label2vec_path, np.array(label2vec).astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for Word2Vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37torch190",
   "language": "python",
   "name": "py37torch190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
